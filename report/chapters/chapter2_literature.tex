\chapter{Literature Review}
\label{ch:literature}

\section{Introduction to Causal Relationship Extraction}

Causal relationship extraction is a fundamental task in Natural Language Processing that aims to identify cause-and-effect relationships from text. This task has significant applications in various domains, including medical informatics, financial analysis, scientific discovery, and historical research. The extraction of causal relationships involves identifying not only the events or entities involved but also the direction of causation and the strength of the causal link.

Causality in natural language can be expressed in numerous ways, ranging from explicit markers such as ``because,'' ``therefore,'' and ``as a result of'' to implicit expressions where causation must be inferred from context, world knowledge, or temporal ordering \cite{jurafsky2009speech}. This variability makes causal relationship extraction a challenging NLP task that has attracted considerable research attention.

\section{Rule-Based Approaches to Causality Detection}

Traditional approaches to causal relationship extraction rely heavily on manually crafted rules and patterns. These methods typically involve:

\subsection{Lexical Pattern Matching}

Early work in causal extraction focused on identifying causal connectives and markers. Researchers compiled lists of causal verbs (e.g., ``cause,'' ``trigger,'' ``lead to,'' ``result in'') and conjunctions (e.g., ``because,'' ``since,'' ``therefore'') that signal causal relationships. Pattern-based systems search for these markers and extract the surrounding text as cause-effect pairs.

Khoo et al. \cite{khoo2000extracting} developed one of the pioneering systems that used graphical patterns to extract causal knowledge from Wall Street Journal texts. Their approach identified patterns such as ``NP causes NP'' and ``NP results in NP'' to extract causal pairs. The system achieved reasonable precision but suffered from low recall due to the limited coverage of predefined patterns.

\subsection{Syntactic Analysis}

More sophisticated rule-based approaches incorporate syntactic analysis to improve extraction accuracy. By parsing sentences and identifying grammatical structures, these systems can better understand the relationships between clauses and phrases.

Dependency parsing has proven particularly useful for causal extraction. The grammatical relationships between words, such as subject-verb-object structures, help identify which entities are involved in causal relationships and in what capacity.

\subsection{Semantic Role Labeling}

Semantic role labeling (SRL) provides a deeper level of analysis by identifying the semantic roles that arguments play in relation to predicates. In the context of causality, SRL can help identify agents (causes) and patients (effects) even when they are not adjacent in the text.

\section{Machine Learning Approaches}

\subsection{Supervised Classification}

Machine learning approaches typically frame causal relationship extraction as a classification problem. Given a pair of events or clauses, the classifier determines whether a causal relationship exists between them.

Feature-based classifiers use handcrafted features derived from:
\begin{itemize}
    \item Lexical features (word forms, lemmas, n-grams)
    \item Syntactic features (POS tags, dependency relations)
    \item Semantic features (WordNet categories, word embeddings)
    \item Positional features (distance between events, relative position)
    \item Discourse features (connectives, discourse markers)
\end{itemize}

Support Vector Machines (SVMs), Random Forests, and Logistic Regression have been commonly used classifiers for this task.

\subsection{Deep Learning Approaches}

The advent of deep learning has significantly advanced causal relationship extraction. Neural network architectures can learn representations automatically from data, reducing the need for manual feature engineering.

Convolutional Neural Networks (CNNs) have been applied to extract local features from text windows around potential causal pairs. Recurrent Neural Networks (RNNs), particularly Long Short-Term Memory (LSTM) networks, can capture long-range dependencies that are often important for identifying causality.

Attention mechanisms allow models to focus on the most relevant parts of the input when making predictions. Self-attention and transformer architectures have proven particularly effective for understanding complex linguistic relationships.

\subsection{Transformer-Based Models}

The introduction of transformer models, beginning with BERT (Bidirectional Encoder Representations from Transformers) \cite{devlin2018bert}, has revolutionized NLP. These models, pre-trained on large corpora, can be fine-tuned for specific tasks including causal relationship classification.

Natural Language Inference (NLI) models, trained to determine entailment, contradiction, or neutral relationships between sentence pairs, have been adapted for causality detection. If a cause sentence ``entails'' an effect sentence (i.e., if the cause is true, the effect is likely true), this provides evidence for a causal relationship.

Models such as DistilBART-MNLI \cite{lewis2019bart}, which is used in this project, combine the efficiency of distilled models with training on the Multi-Genre Natural Language Inference corpus \cite{williams2018mnli}, making them suitable for zero-shot classification tasks including causality assessment.

\section{Cross-Document Relationship Extraction}

Most early work on relationship extraction focused on within-document extraction, where both entities or events appear in the same text. Cross-document extraction presents additional challenges:

\subsection{Entity Resolution}

When extracting relationships across documents, it is essential to determine when references in different documents refer to the same entity or event. This entity resolution or coreference resolution problem becomes more complex when dealing with historical texts where entities may be referred to by multiple names or titles.

\subsection{Topic Modeling and Document Similarity}

To identify potentially related documents, techniques such as topic modeling (LDA, LSA) \cite{blei2003latent} and document similarity measures (cosine similarity, TF-IDF) \cite{manning1999foundations} are employed. These methods help narrow down the search space when looking for cross-document relationships.

\subsection{Knowledge Graph Construction}

Cross-document extraction is often framed as knowledge graph construction, where entities and events from multiple documents are nodes, and relationships (including causal relationships) are edges. This representation facilitates reasoning and querying across the entire document collection.

\section{NLP for Historical Documents}

Historical documents present unique challenges for NLP systems:

\subsection{Language Evolution}

The English language has evolved over time, and texts from the early 20th century may contain archaic vocabulary, spelling variations, and grammatical structures that differ from modern usage. NLP tools trained on contemporary texts may not perform optimally on historical documents.

\subsection{OCR Errors}

Many historical documents are digitized through Optical Character Recognition (OCR), which can introduce errors, particularly with degraded or handwritten documents. These errors can affect downstream NLP tasks.

\subsection{Genre Variability}

Historical collections often contain diverse document types, including personal correspondence, official records, newspaper articles, and literary works. Each genre has distinct characteristics that affect language use and the expression of causality.

\subsection{Cultural and Contextual Knowledge}

Understanding historical texts often requires domain knowledge about the period, including historical events, social norms, and cultural references. This world knowledge is essential for accurate interpretation and relationship extraction.

\section{Evaluation Metrics for Relationship Extraction}

Evaluating causal relationship extraction systems presents methodological challenges:

\subsection{Precision and Recall}

Standard information extraction metrics include:
\begin{itemize}
    \item \textbf{Precision:} The proportion of extracted relationships that are correct
    \item \textbf{Recall:} The proportion of actual relationships that are extracted
    \item \textbf{F1-score:} The harmonic mean of precision and recall
\end{itemize}

\subsection{Confidence Scoring}

Many systems assign confidence scores to extracted relationships, allowing for precision-recall trade-offs. Higher confidence thresholds typically yield higher precision but lower recall.

\subsection{Human Evaluation}

Given the complexity and subjectivity of causality, human evaluation remains an important component of system assessment. Domain experts can evaluate samples of extracted relationships for correctness and relevance.

\section{Visualization of Causal Networks}

Visual representation of extracted causal relationships aids interpretation and analysis:

\subsection{Directed Graphs}

Causal relationships naturally lend themselves to directed graph representation, with nodes representing events or entities and directed edges representing causal links.

\subsection{Network Analysis Metrics}

Graph-theoretic measures such as centrality, clustering coefficient, and path length provide quantitative insights into the structure of causal networks.

\subsection{Interactive Visualization}

Interactive visualization tools allow users to explore causal networks, filter by confidence level, and drill down into specific relationships.

\section{Summary}

This literature review has covered the key approaches and techniques relevant to causal relationship extraction from historical texts. The project draws on this body of work by combining rule-based linguistic patterns with transformer-based NLI models, applying these techniques to a unique corpus of World War I documents. The following chapter details the specific methodology employed in this project.
